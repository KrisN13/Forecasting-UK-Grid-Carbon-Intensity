{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38afcc3f-9121-4294-a91c-ca1d651903fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3b44e2-6bb6-4155-8cd5-c5b6b1336447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for carbon intensity dataset\n",
    "PATH = \"C:/Users/Krist/OneDrive/Documents/Data Analysis/Practice/Carbon/data/processed/df_carbon.parquet\"\n",
    "\n",
    "# Keeps the DATETIME column as an index\n",
    "df_carbon = pd.read_parquet(PATH)\n",
    "\n",
    "# Sort Ascending order by index (DATETIME)\n",
    "df_carbon = df_carbon.sort_index()\n",
    "\n",
    "# Keep records within the modern period due to less fluctuation in data readings (determined in Notebook 02)\n",
    "df_carbon = df_carbon[df_carbon.index >= \"2020-01-01\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea315b0-1f0f-4c34-8102-e0dceeaabcdf",
   "metadata": {},
   "source": [
    "+ Time features\n",
    "+ Lag features of CARBON_INTENSITY\n",
    "+ Lag-1 of key mix features (to avoid leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e721428-3bd9-47a8-bccb-234506146bd6",
   "metadata": {},
   "source": [
    "# Time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a6a390a-c867-44ee-be99-19fc6ca659d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df[\"hour\"] = df.index.hour\n",
    "    df[\"dayofweek\"] = df.index.dayofweek  # 0=Mon\n",
    "    df[\"is_weekend\"] = (df[\"dayofweek\"] >= 5).astype(int)\n",
    "    df[\"month\"] = df.index.month\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bce4e9-2f92-4bbe-9086-20f5b80d31fc",
   "metadata": {},
   "source": [
    "# Lag Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bbeef31-b455-49ea-a49a-1389f44f7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_lag_features(df: pd.DataFrame, lags=(1, 24, 168)) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for lag in lags:\n",
    "        df[f\"ci_lag_{lag}\"] = df[\"CARBON_INTENSITY\"].shift(lag)\n",
    "    # 24h rolling mean to smooth noise\n",
    "    df[\"ci_rollmean_24\"] = df[\"CARBON_INTENSITY\"].rolling(24).mean()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff213b9-35da-4fa3-bb86-3f36efb0ae4f",
   "metadata": {},
   "source": [
    "# Lagged mix features (1-hour lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae4f5ba4-25ba-49c3-a4fb-69a9dcc22972",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIX_COLS = [\n",
    "    \"FOSSIL\", \"COAL\", \"GAS\", \"NUCLEAR\", \"STORAGE\",\n",
    "    \"GENERATION\", \"WIND\", \"HYDRO\", \"SOLAR\", \"BIOMASS\",\n",
    "    \"RENEWABLE\", \"OTHER\",\n",
    "]\n",
    "\n",
    "def add_mix_lag1(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for col in MIX_COLS:\n",
    "        df[f\"{col}_lag1\"] = df[col].shift(1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40f24f00-4f9c-445d-9c98-3d42430c191b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the full Dataframe\n",
    "df_feat = df_carbon.copy()\n",
    "df_feat = add_time_features(df_feat)\n",
    "df_feat = add_lag_features(df_feat, lags=(1, 24, 168))\n",
    "df_feat = add_mix_lag1(df_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46c0333a-f2dc-4d41-91f7-3609d06df2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define target and drop rows with NaNs created by shifting/rolling\n",
    "TARGET_COL = \"CARBON_INTENSITY\"\n",
    "\n",
    "# Drop rows with any NaNs (early lags/rolling)\n",
    "df_model = df_feat.dropna().copy()\n",
    "\n",
    "y = df_model[TARGET_COL]\n",
    "\n",
    "# Exclude original carbon intensity and any raw mix columns from features,\n",
    "# keep only engineered features + lagged mix.\n",
    "feature_cols = [\n",
    "    col for col in df_model.columns\n",
    "    if col not in (\n",
    "        [\"CARBON_INTENSITY\"] + MIX_COLS + [\"LOW_CARBON\", \"ZERO_CARBON\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "X = df_model[feature_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcea2081-5889-4670-86fe-f6052f3ac901",
   "metadata": {},
   "source": [
    "# Train / val / test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29f95688-2eed-452c-ae21-3d85bf50d743",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = (df_model.index.year >= 2020) & (df_model.index.year <= 2023)\n",
    "val_mask   = (df_model.index.year == 2024)\n",
    "test_mask  = (df_model.index.year == 2025)\n",
    "\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val,   y_val   = X[val_mask],   y[val_mask]\n",
    "X_test,  y_test  = X[test_mask],  y[test_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee4ea5e-ae9d-48e9-a97e-83700e053db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34896, 20), (8784, 20), (7786, 20))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity Check - Sizes\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07e74a3a-98be-468b-b538-7ad904d4bb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared evaluation helper\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_v, y_v, X_te, y_te):\n",
    "    y_tr_pred = model.predict(X_tr)\n",
    "    y_v_pred  = model.predict(X_v)\n",
    "    y_te_pred = model.predict(X_te)\n",
    "\n",
    "    def metrics(y_true, y_pred):\n",
    "        mae  = mean_absolute_error(y_true, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        return mae, rmse\n",
    "\n",
    "    mae_tr, rmse_tr = metrics(y_tr, y_tr_pred)\n",
    "    mae_v,  rmse_v  = metrics(y_v,  y_v_pred)\n",
    "    mae_te, rmse_te = metrics(y_te, y_te_pred)\n",
    "\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"Train: MAE={mae_tr:.2f}, RMSE={rmse_tr:.2f}\")\n",
    "    print(f\"Val:   MAE={mae_v:.2f}, RMSE={rmse_v:.2f}\")\n",
    "    print(f\"Test:  MAE={mae_te:.2f}, RMSE={rmse_te:.2f}\")\n",
    "\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"mae_tr\": mae_tr, \"rmse_tr\": rmse_tr,\n",
    "        \"mae_v\": mae_v,   \"rmse_v\": rmse_v,\n",
    "        \"mae_te\": mae_te, \"rmse_te\": rmse_te,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715f4829-b325-455a-bf29-546c64e328a3",
   "metadata": {},
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2c39b9e-bfc3-40cb-8e11-c6b80bb8ef80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Ridge regression ===\n",
      "Train: MAE=8.05, RMSE=10.73\n",
      "Val:   MAE=8.08, RMSE=10.95\n",
      "Test:  MAE=8.84, RMSE=11.74\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha=1.0, random_state=42)\n",
    "\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "ridge_results = evaluate_model(\n",
    "    \"Ridge regression\",\n",
    "    ridge,\n",
    "    X_train, y_train,\n",
    "    X_val,   y_val,\n",
    "    X_test,  y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78504e2-686b-496b-9fa5-80f7e093c4fb",
   "metadata": {},
   "source": [
    "A simple linear model with time features + lags does not capture the non-linear behaviour of the grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeca781d-8cad-4ec1-b600-149f10327aa1",
   "metadata": {},
   "source": [
    "# HistGradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b324a48-d21d-40f1-8fc2-165d06cfd205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HistGradientBoostingRegressor ===\n",
      "Train: MAE=4.86, RMSE=6.44\n",
      "Val:   MAE=5.65, RMSE=7.63\n",
      "Test:  MAE=5.97, RMSE=7.98\n"
     ]
    }
   ],
   "source": [
    "# This algorithm is faster than traditional gradient boosting for large datasets\n",
    "gboost = HistGradientBoostingRegressor(\n",
    "    max_depth=8,          # Maximum depth of the trees (controls complexity)\n",
    "    learning_rate=0.05,   # Small learning rate for better generalization\n",
    "    max_iter=300,         # Number of boosting iterations (trees)\n",
    "    random_state=42       # Set seed for reproducibility\n",
    ")\n",
    "\n",
    "# Train the model on the training data\n",
    "gboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model's performance on training, validation and test sets\n",
    "# Results typically include metrics like RMSE, MAE, RÂ² score\n",
    "gboost_results = evaluate_model(\n",
    "    \"HistGradientBoostingRegressor\",  # Model name for reporting\n",
    "    gboost,                           # Trained model instance\n",
    "    X_train, y_train,                 # Training data\n",
    "    X_val,   y_val,                   # Validation data\n",
    "    X_test,  y_test,                  # Test data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a483bb7-84ef-4b49-8d11-38b64edb6ccc",
   "metadata": {},
   "source": [
    "# Saving Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c6abdc7-d397-4ec7-a808-a2c3043853fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = gboost.predict(X_train)\n",
    "pred_val   = gboost.predict(X_val)\n",
    "pred_test  = gboost.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7c7bfba-4e01-45eb-8fb1-acd37bef5184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame({\n",
    "    \"CI_actual\": y,        # full series\n",
    "})\n",
    "\n",
    "df_preds[\"CI_pred\"] = np.nan\n",
    "\n",
    "df_preds.loc[y_train.index, \"CI_pred\"] = pred_train\n",
    "df_preds.loc[y_val.index,   \"CI_pred\"] = pred_val\n",
    "df_preds.loc[y_test.index,  \"CI_pred\"] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3015ffa-192c-460a-87e8-da222020fb85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved to C:/Users/Krist/OneDrive/Documents/Data Analysis/Practice/Carbon/data/predictions/ci_predictions.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"../data/predictions\", exist_ok=True)\n",
    "df_preds.to_parquet(\"C:/Users/Krist/OneDrive/Documents/Data Analysis/Practice/Carbon/data/predictions/ci_predictions.parquet\")\n",
    "print(\"DataFrame saved to C:/Users/Krist/OneDrive/Documents/Data Analysis/Practice/Carbon/data/predictions/ci_predictions.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94bc20a5-2116-40cd-9ba6-428734c01de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 51466 entries, 2020-01-08 00:00:00+00:00 to 2025-11-21 09:00:00+00:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   CI_actual  51466 non-null  float64\n",
      " 1   CI_pred    51466 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "df_preds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a2b54-1b7d-4b3a-aa0c-a9d7a706a864",
   "metadata": {},
   "source": [
    "# Feature importance ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec1ee62c-4c8c-4ebf-b033-5cc2a0d1cfd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ci_lag_1           1.941800\n",
       "hour               0.040015\n",
       "SOLAR_lag1         0.013942\n",
       "ci_rollmean_24     0.002848\n",
       "dayofweek          0.000955\n",
       "GAS_lag1           0.000567\n",
       "RENEWABLE_lag1     0.000439\n",
       "OTHER_lag1         0.000365\n",
       "month              0.000291\n",
       "STORAGE_lag1       0.000276\n",
       "WIND_lag1          0.000271\n",
       "GENERATION_lag1    0.000262\n",
       "ci_lag_24          0.000142\n",
       "HYDRO_lag1         0.000097\n",
       "FOSSIL_lag1        0.000088\n",
       "ci_lag_168         0.000041\n",
       "is_weekend         0.000000\n",
       "COAL_lag1         -0.000001\n",
       "BIOMASS_lag1      -0.000011\n",
       "NUCLEAR_lag1      -0.000075\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calculate permutation importance - this evaluates feature importance by measuring\n",
    "# how much model performance decreases when a feature is randomly shuffled\n",
    "perm_importance = permutation_importance(\n",
    "    gboost,  # The trained model to evaluate\n",
    "    X_test,  # Using test data for evaluation (could also use X_train)\n",
    "    y_test,  # Target values for test data (could also use y_train)\n",
    "    n_repeats=10,  # Number of times to permute each feature (more repeats = more stable results)\n",
    "    random_state=42  # For reproducibility\n",
    ")\n",
    "\n",
    "# Create a pandas Series with the mean importance values for each feature\n",
    "fi = pd.Series(perm_importance.importances_mean, index=feature_cols)\n",
    "# Sort features by importance in descending order and display the top 20\n",
    "fi.sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee84658f-a350-4ccf-907c-75fe4f5e4cd7",
   "metadata": {},
   "source": [
    "The modern UK grid is highly autoregressive, especially after 2020.\n",
    "Carbon intensity is explained mostly by the previous hour and the daily demand curve, along with solar, are adding a predictable midday effect.\n",
    "Mix-based features add value but do not dominate because the grid is now renewables-driven and less volatile when it comes to fossil output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
